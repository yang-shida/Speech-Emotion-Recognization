{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa, librosa.display\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label is from 1-8, so I added a place holder at position 0\n",
    "labels_names = np.array(['place holder', 'neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprise'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X_test, y_test):\n",
    "    \n",
    "    # run ensemble learners\n",
    "    # min-max normalize\n",
    "    X_test_scaled = preprocessing.MinMaxScaler(feature_range=(0, 1)).fit(X_test.T)\n",
    "    X_test_scaled = X_test_scaled.transform(X_test.T).T\n",
    "    \n",
    "    # compute MFCC\n",
    "    sr = 44100\n",
    "    n_mfcc = 13\n",
    "    n_fft_mfcc = 2048\n",
    "    hop_length_mfcc = 512\n",
    "\n",
    "    MFCC_feature_matrix = []\n",
    "    for i in range(X_test_scaled.shape[0]):\n",
    "        MFCC_feature_matrix += [librosa.feature.mfcc(X_test_scaled[i], sr = sr, n_mfcc = n_mfcc, n_fft = n_fft_mfcc, hop_length = hop_length_mfcc)]\n",
    "    MFCC_feature_matrix = np.array(MFCC_feature_matrix)\n",
    "\n",
    "    # Add a depth of 1 so the data can be used in CNN\n",
    "    X_test1 = MFCC_feature_matrix[..., np.newaxis]\n",
    "    \n",
    "    # compute output softmax\n",
    "    pred_total = np.zeros((X_test_scaled.shape[0], 9))\n",
    "\n",
    "    # run each learner and add their softmax output\n",
    "    for i in range(20):\n",
    "        model = keras.models.load_model('Ensemble_Learners/model'+str(i)+'.h5')\n",
    "        pred_class = model.predict(X_test1)\n",
    "\n",
    "        pred_total += pred_class\n",
    "        \n",
    "    # run knn\n",
    "    # MFCC\n",
    "    sr = 44100\n",
    "    n_mfcc = 13\n",
    "    n_fft_mfcc = 2048\n",
    "    hop_length_mfcc = 512\n",
    "\n",
    "    MFCC_feature_matrix = []\n",
    "    for i in range(X_test.shape[0]):\n",
    "        MFCC_feature_matrix += [librosa.feature.mfcc(X_test[i], sr = sr, n_mfcc = n_mfcc, n_fft = n_fft_mfcc, hop_length = hop_length_mfcc)]\n",
    "    MFCC_feature_matrix = np.array(MFCC_feature_matrix)\n",
    "    MFCC_feature_matrix = np.mean(MFCC_feature_matrix, axis=2)\n",
    "\n",
    "    # STFT\n",
    "    n_fft_stft = 4096\n",
    "    hop_length_stft = 2048\n",
    "\n",
    "    STFT_feature_matrix = []\n",
    "    for i in range(X_test.shape[0]):\n",
    "        STFT_feature_matrix += [np.abs(librosa.core.stft(X_test[i], n_fft = n_fft_stft, hop_length = hop_length_stft))]\n",
    "    STFT_feature_matrix = np.array(STFT_feature_matrix)\n",
    "    STFT_feature_matrix = np.mean(STFT_feature_matrix, axis=2)\n",
    "\n",
    "    FeatureMatrix = np.concatenate((MFCC_feature_matrix, STFT_feature_matrix), axis=1)\n",
    "\n",
    "    # load knn model and make prediction\n",
    "    loaded_model = pickle.load(open('model_knn', 'rb'))\n",
    "    pred_yp_knn_s1 = loaded_model.predict(FeatureMatrix)\n",
    "    \n",
    "    # get the top3 choice of ensemble learners\n",
    "    cnn_1st_ind = pred_total.argsort()[:,-1]\n",
    "    cnn_2st_ind = pred_total.argsort()[:,-2]\n",
    "    cnn_3st_ind = pred_total.argsort()[:,-3]\n",
    "\n",
    "    THRESHOLD = 4\n",
    "\n",
    "    combined_class_pred = []\n",
    "\n",
    "    for i in range(len(pred_yp_knn_s1)):\n",
    "        # if first choice is THRESHOLD times or greater than the second choice, we choose first choice\n",
    "        if pred_total[i][cnn_1st_ind[i]] > 4*pred_total[i][cnn_2st_ind[i]]:\n",
    "            combined_class_pred += [cnn_1st_ind[i]]\n",
    "        else:\n",
    "            # otherwise, there is not a clear win, so we use knn results to help make final decision\n",
    "            if pred_yp_knn_s1[i] == cnn_1st_ind[i]:\n",
    "                combined_class_pred += [cnn_1st_ind[i]]\n",
    "            elif pred_yp_knn_s1[i] == cnn_2st_ind[i]:\n",
    "                combined_class_pred += [cnn_2st_ind[i]]\n",
    "            elif pred_yp_knn_s1[i] == cnn_3st_ind[i]:\n",
    "                combined_class_pred += [cnn_3st_ind[i]]\n",
    "            else:\n",
    "                combined_class_pred += [cnn_1st_ind[i]]\n",
    "\n",
    "    combined_acc_score = accuracy_score(y_test, combined_class_pred)\n",
    "    print(combined_acc_score)\n",
    "    \n",
    "    # output accuracy and prediction labels\n",
    "    return combined_acc_score, combined_class_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "# you need to change this path with your own directory\n",
    "path = 'C:/Users/catia/Dropbox (UFL)/Teaching/2020 Fall/EEE 4773 Fundamentals of Machine Learning/GitHub/Final-Project/Code and Reports/Dataset/'\n",
    "\n",
    "X_train = np.load(path+'data_training.npy')\n",
    "y_train = np.load(path+'labels_training.npy')\n",
    "\n",
    "X_test = np.load(path+'data_test.npy')\n",
    "y_test = np.load(path+'labels_test.npy')\n",
    "\n",
    "X_hardtest = np.load(path+'data_hardtest.npy',allow_pickle=True).astype('float')\n",
    "y_hardtest = np.load(path+'labels_hardtest.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2400, 100000), (2400,), (640, 100000), (640,), (340, 100000), (340,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_hardtest.shape, y_hardtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\catia\\anaconda3\\envs\\tf231\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator KNeighborsClassifier from version 0.23.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9775\n"
     ]
    }
   ],
   "source": [
    "acc_score, pred_label = test(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\catia\\anaconda3\\envs\\tf231\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator KNeighborsClassifier from version 0.23.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.853125\n"
     ]
    }
   ],
   "source": [
    "acc_score, pred_label = test(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 4, 2, 1, 1, 2, 2, 2,\n",
       "        1, 1, 1, 4, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 4, 4, 2, 6,\n",
       "        7, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 6,\n",
       "        2, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 1, 4, 2, 2, 1, 2, 2, 2,\n",
       "        2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 6, 8, 8, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 2,\n",
       "        4, 6, 4, 7, 3, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 6, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 3, 4,\n",
       "        4, 4, 4, 4, 2, 4, 1, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 4, 5, 8, 5, 5, 5, 5, 5, 5, 5, 3, 5, 6, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 8, 6, 5, 5, 5, 5, 5, 5,\n",
       "        5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 5, 6, 8, 4, 6, 8,\n",
       "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6,\n",
       "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 3, 6,\n",
       "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 2, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 3, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 5, 7, 5, 7, 7, 5, 7, 7, 5, 2, 7, 7, 8, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 6, 7, 7, 8, 8, 8, 6, 3, 8, 8, 8, 8, 6, 3, 8,\n",
       "        8, 8, 8, 8, 8, 8, 5, 8, 8, 8, 8, 8, 8, 8, 8, 4, 8, 8, 8, 8, 8, 8,\n",
       "        8, 8, 8, 8, 8, 5, 5, 8, 8, 8, 8, 8, 8, 8, 6, 5, 8, 8, 8, 6, 8, 5,\n",
       "        3, 8, 3, 3, 3, 8, 3, 8, 8, 8, 6, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "        8, 8], dtype=int64),\n",
       " array(['neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "        'happy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "        'neutral', 'neutral', 'neutral', 'sad', 'calm', 'neutral',\n",
       "        'neutral', 'calm', 'calm', 'calm', 'neutral', 'neutral', 'neutral',\n",
       "        'sad', 'neutral', 'neutral', 'calm', 'neutral', 'neutral',\n",
       "        'neutral', 'neutral', 'calm', 'neutral', 'neutral', 'neutral',\n",
       "        'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "        'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "        'neutral', 'calm', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "        'neutral', 'neutral', 'neutral', 'neutral', 'calm', 'happy',\n",
       "        'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "        'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "        'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "        'neutral', 'neutral', 'calm', 'calm', 'calm', 'sad', 'sad', 'calm',\n",
       "        'fearful', 'disgust', 'neutral', 'neutral', 'neutral', 'calm',\n",
       "        'calm', 'calm', 'calm', 'calm', 'calm', 'calm', 'calm', 'calm',\n",
       "        'calm', 'calm', 'calm', 'neutral', 'calm', 'calm', 'calm', 'calm',\n",
       "        'fearful', 'calm', 'disgust', 'calm', 'calm', 'calm', 'calm',\n",
       "        'calm', 'calm', 'calm', 'calm', 'calm', 'calm', 'sad', 'sad',\n",
       "        'neutral', 'sad', 'calm', 'calm', 'neutral', 'calm', 'calm',\n",
       "        'calm', 'calm', 'calm', 'calm', 'calm', 'neutral', 'calm',\n",
       "        'neutral', 'calm', 'calm', 'calm', 'calm', 'calm', 'calm', 'calm',\n",
       "        'calm', 'calm', 'calm', 'calm', 'calm', 'calm', 'calm', 'calm',\n",
       "        'calm', 'calm', 'calm', 'calm', 'calm', 'calm', 'happy', 'happy',\n",
       "        'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "        'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "        'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "        'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'angry',\n",
       "        'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "        'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "        'fearful', 'surprise', 'surprise', 'happy', 'happy', 'happy',\n",
       "        'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "        'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "        'happy', 'happy', 'fearful', 'happy', 'happy', 'happy', 'happy',\n",
       "        'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
       "        'happy', 'happy', 'sad', 'calm', 'sad', 'fearful', 'sad',\n",
       "        'disgust', 'happy', 'sad', 'happy', 'sad', 'sad', 'sad', 'sad',\n",
       "        'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'fearful', 'sad',\n",
       "        'fearful', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad',\n",
       "        'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'calm', 'sad', 'sad',\n",
       "        'sad', 'sad', 'sad', 'sad', 'sad', 'happy', 'sad', 'sad', 'sad',\n",
       "        'sad', 'sad', 'calm', 'sad', 'neutral', 'sad', 'sad', 'calm',\n",
       "        'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad',\n",
       "        'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad',\n",
       "        'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'angry', 'angry',\n",
       "        'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry',\n",
       "        'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry',\n",
       "        'angry', 'sad', 'angry', 'surprise', 'angry', 'angry', 'angry',\n",
       "        'angry', 'angry', 'angry', 'angry', 'happy', 'angry', 'fearful',\n",
       "        'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry',\n",
       "        'angry', 'angry', 'angry', 'angry', 'angry', 'disgust', 'angry',\n",
       "        'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry',\n",
       "        'angry', 'surprise', 'surprise', 'angry', 'angry', 'angry',\n",
       "        'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry',\n",
       "        'angry', 'angry', 'angry', 'fearful', 'surprise', 'fearful',\n",
       "        'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry',\n",
       "        'angry', 'angry', 'angry', 'fearful', 'fearful', 'fearful',\n",
       "        'fearful', 'fearful', 'fearful', 'fearful', 'surprise', 'fearful',\n",
       "        'fearful', 'fearful', 'fearful', 'angry', 'fearful', 'surprise',\n",
       "        'sad', 'fearful', 'surprise', 'fearful', 'fearful', 'fearful',\n",
       "        'fearful', 'fearful', 'fearful', 'fearful', 'fearful', 'fearful',\n",
       "        'fearful', 'fearful', 'fearful', 'fearful', 'fearful', 'fearful',\n",
       "        'fearful', 'angry', 'fearful', 'fearful', 'fearful', 'fearful',\n",
       "        'fearful', 'fearful', 'fearful', 'fearful', 'fearful', 'fearful',\n",
       "        'fearful', 'fearful', 'fearful', 'fearful', 'fearful', 'fearful',\n",
       "        'fearful', 'fearful', 'fearful', 'fearful', 'fearful', 'fearful',\n",
       "        'fearful', 'happy', 'fearful', 'happy', 'fearful', 'fearful',\n",
       "        'fearful', 'fearful', 'fearful', 'fearful', 'fearful', 'fearful',\n",
       "        'fearful', 'fearful', 'fearful', 'fearful', 'fearful', 'fearful',\n",
       "        'fearful', 'fearful', 'fearful', 'fearful', 'fearful', 'disgust',\n",
       "        'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust',\n",
       "        'disgust', 'disgust', 'calm', 'disgust', 'disgust', 'disgust',\n",
       "        'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust',\n",
       "        'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust',\n",
       "        'disgust', 'angry', 'fearful', 'disgust', 'disgust', 'disgust',\n",
       "        'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust',\n",
       "        'happy', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust',\n",
       "        'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust',\n",
       "        'disgust', 'disgust', 'disgust', 'disgust', 'angry', 'disgust',\n",
       "        'angry', 'disgust', 'disgust', 'angry', 'disgust', 'disgust',\n",
       "        'angry', 'calm', 'disgust', 'disgust', 'surprise', 'disgust',\n",
       "        'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust',\n",
       "        'disgust', 'disgust', 'disgust', 'disgust', 'fearful', 'disgust',\n",
       "        'disgust', 'surprise', 'surprise', 'surprise', 'fearful', 'happy',\n",
       "        'surprise', 'surprise', 'surprise', 'surprise', 'fearful', 'happy',\n",
       "        'surprise', 'surprise', 'surprise', 'surprise', 'surprise',\n",
       "        'surprise', 'surprise', 'angry', 'surprise', 'surprise',\n",
       "        'surprise', 'surprise', 'surprise', 'surprise', 'surprise',\n",
       "        'surprise', 'sad', 'surprise', 'surprise', 'surprise', 'surprise',\n",
       "        'surprise', 'surprise', 'surprise', 'surprise', 'surprise',\n",
       "        'surprise', 'surprise', 'angry', 'angry', 'surprise', 'surprise',\n",
       "        'surprise', 'surprise', 'surprise', 'surprise', 'surprise',\n",
       "        'fearful', 'angry', 'surprise', 'surprise', 'surprise', 'fearful',\n",
       "        'surprise', 'angry', 'happy', 'surprise', 'happy', 'happy',\n",
       "        'happy', 'surprise', 'happy', 'surprise', 'surprise', 'surprise',\n",
       "        'fearful', 'surprise', 'surprise', 'surprise', 'surprise',\n",
       "        'surprise', 'surprise', 'surprise', 'surprise', 'surprise',\n",
       "        'surprise', 'surprise', 'surprise', 'surprise'], dtype='<U12'))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_label = np.array(pred_label)\n",
    "pred_label, labels_names[pred_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[68,  8,  2,  2,  0,  0,  0,  0],\n",
       "       [ 9, 62,  0,  5,  0,  2,  2,  0],\n",
       "       [ 0,  0, 75,  0,  1,  2,  0,  2],\n",
       "       [ 1,  4,  3, 68,  0,  3,  1,  0],\n",
       "       [ 0,  0,  1,  1, 70,  3,  1,  4],\n",
       "       [ 0,  0,  2,  1,  2, 72,  0,  3],\n",
       "       [ 0,  2,  1,  0,  5,  2, 69,  1],\n",
       "       [ 0,  0,  7,  1,  5,  5,  0, 62]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\catia\\anaconda3\\envs\\tf231\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator KNeighborsClassifier from version 0.23.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "acc_score, pred_label = test(X_hardtest, y_hardtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  1,  0, 10,  0,  1,  8,  0],\n",
       "       [ 0, 61, 11,  3,  3,  1,  1,  0,  0],\n",
       "       [ 0,  8, 60,  1,  6,  0,  2,  3,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  1,  2,  2, 72,  0,  3],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  7,  2,  3,  6,  0, 62]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_hardtest, pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
